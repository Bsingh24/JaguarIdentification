{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "478b4e44-6514-4877-ac34-4d1976ca7dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Resnet import ResNet, Block\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision.io import decode_image, ImageReadMode\n",
    "from torch.utils.data import Dataset, Sampler, DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ed9deb-b889-403c-8573-2b9182dddc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(label_mapping, n_classes, n_samples):\n",
    "    all_classes = list(label_mapping.keys())\n",
    "    batches = []\n",
    "\n",
    "    label_mapping_copy = {c: indices for c, indices in label_mapping.items()}\n",
    "\n",
    "    while True:\n",
    "        available_classes = [c for c in all_classes if len(label_mapping_copy[c]) > 0]\n",
    "        if len(available_classes) < n_classes:\n",
    "            break\n",
    "\n",
    "        selected_classes = random.sample(available_classes, n_classes)\n",
    "        batch = []\n",
    "\n",
    "        for cls in selected_classes:\n",
    "            indices = label_mapping_copy[cls]\n",
    "\n",
    "            if len(indices) >= n_samples:\n",
    "                chosen = indices[:n_samples]\n",
    "                label_mapping_copy[cls] = indices[n_samples:]\n",
    "            else:\n",
    "                chosen = indices + random.choices(indices, k=n_samples - len(indices))\n",
    "                label_mapping_copy[cls] = []\n",
    "\n",
    "            batch.extend(chosen)\n",
    "\n",
    "        batches.append(batch)\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "class BalancedBatchSampler(Sampler):\n",
    "    def __init__(self, labels, n_classes, n_samples):\n",
    "        self.labels = labels\n",
    "        self.n_classes = n_classes \n",
    "        self.n_samples = n_samples  \n",
    "\n",
    "        self.label_mapping = defaultdict(list)\n",
    "        for idx, label in enumerate(labels):\n",
    "            self.label_mapping[int(label)].append(idx)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for cls in self.label_mapping:\n",
    "            random.shuffle(self.label_mapping[cls])\n",
    "\n",
    "        batches = create_batches(self.label_mapping, self.n_classes, self.n_samples)\n",
    "        for batch in batches:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        batches = create_batches(self.label_mapping, self.n_classes, self.n_samples)\n",
    "        return len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dcce175-22d4-4b83-8268-7fb16e8b3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, annotation_file, img_dir, transform=None):\n",
    "        self.img_label = pd.read_csv(annotation_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_label.iloc[idx, 0])\n",
    "        image = decode_image(img_path, mode=ImageReadMode.RGB)\n",
    "        label = self.img_label.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e97a30-89dd-47d3-a244-0e1ca702422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.Resize(256),\n",
    "    v2.CenterCrop(224),\n",
    "    v2.ToDtype(torch.float32, scale=True)])\n",
    "train_data = ImageDataset('Data/train_data.csv', 'Data/train/', transform)\n",
    "valid_data = ImageDataset('Data/valid_data.csv', 'Data/train/', transform)\n",
    "test_data = ImageDataset('Data/test_data.csv', 'Data/train/', transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb6dd73-0583-47d0-98ab-74d4187395f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = ResNet(Block, [3, 4, 6, 3], image_channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a45e6df-ef5c-4e4d-b977-06818cc7f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/train_data.csv')\n",
    "label_tensor = torch.tensor(df['encoded_ground_truth'].values)\n",
    "\n",
    "sampler = BalancedBatchSampler(label_tensor, 5, 3)\n",
    "\n",
    "dataloader = DataLoader(train_data, batch_sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b4a9e15-f5fb-41e4-8dc3-e0d4244016c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    x = batch[0]\n",
    "    y = batch[1]\n",
    "    pred = resnet_model(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01045f96-bb70-4145-af14-eb6dadbc441e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
