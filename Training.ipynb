{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "478b4e44-6514-4877-ac34-4d1976ca7dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Resnet import ResNet, Block, create_pairs, create_tensors\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.nn import TripletMarginLoss\n",
    "from torchvision.io import decode_image, ImageReadMode\n",
    "from torch.utils.data import Dataset, Sampler, DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torch.optim import Adam\n",
    "from collections import defaultdict\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ed9deb-b889-403c-8573-2b9182dddc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "creates batches with a size of 15, ensuring we are using all samples provided at random.\n",
    "\"\"\"\n",
    "\n",
    "def create_batches(label_mapping, n_classes, n_samples):\n",
    "    all_classes = list(label_mapping.keys())\n",
    "    batches = []\n",
    "    label_mapping_copy = label_mapping.copy()\n",
    "    while True:\n",
    "        available_classes = [c for c in all_classes if len(label_mapping_copy[c]) > 0] # Keep only classes if they are still available.\n",
    "        # Exit if we have less\n",
    "        if len(available_classes) < n_classes: \n",
    "            break\n",
    "\n",
    "        # Ensures that we will at least have 1 example of every label pair\n",
    "        selected_classes = random.sample(available_classes, n_classes)\n",
    "        batch = []\n",
    "\n",
    "        for cls in selected_classes:\n",
    "            indices = label_mapping_copy[cls]\n",
    "            # If there are not enough examples to sample from, we re-select a sample from the shortened list. Empty the list after\n",
    "            if len(indices) >= n_samples:\n",
    "                chosen = indices[:n_samples]\n",
    "                label_mapping_copy[cls] = indices[n_samples:]\n",
    "            else:\n",
    "                chosen = indices + random.choices(indices, k=(n_samples - len(indices)))\n",
    "                label_mapping_copy[cls] = []\n",
    "\n",
    "            batch.extend(chosen)\n",
    "\n",
    "        batches.append(batch)\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "class BalancedBatchSampler(Sampler):\n",
    "    def __init__(self, labels, n_classes, n_samples):\n",
    "        self.labels = labels\n",
    "        self.n_classes = n_classes \n",
    "        self.n_samples = n_samples  \n",
    "\n",
    "        self.label_mapping = defaultdict(list)\n",
    "        for idx, label in enumerate(labels):\n",
    "            self.label_mapping[int(label)].append(idx)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for cls in self.label_mapping:\n",
    "            random.shuffle(self.label_mapping[cls])\n",
    "\n",
    "        batches = create_batches(self.label_mapping, self.n_classes, self.n_samples)\n",
    "        for batch in batches:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        batches = create_batches(self.label_mapping, self.n_classes, self.n_samples)\n",
    "        return len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dcce175-22d4-4b83-8268-7fb16e8b3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, annotation_file, img_dir, transform=None):\n",
    "        self.img_label = pd.read_csv(annotation_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_label.iloc[idx, 0])\n",
    "        image = decode_image(img_path, mode=ImageReadMode.RGB)\n",
    "        label = self.img_label.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e97a30-89dd-47d3-a244-0e1ca702422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.Resize(256),\n",
    "    v2.CenterCrop(224),\n",
    "    v2.ToDtype(torch.float32, scale=True)])\n",
    "train_data = ImageDataset('Data/train_data.csv', 'Data/train/', transform)\n",
    "valid_data = ImageDataset('Data/valid_data.csv', 'Data/train/', transform)\n",
    "test_data = ImageDataset('Data/test_data.csv', 'Data/train/', transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a45e6df-ef5c-4e4d-b977-06818cc7f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/train_data.csv')\n",
    "label_tensor = torch.tensor(df['encoded_ground_truth'].values)\n",
    "\n",
    "sampler = BalancedBatchSampler(label_tensor, 5, 3)\n",
    "\n",
    "dataloader = DataLoader(train_data, batch_sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bba06369-eb7b-4189-8cfd-0b5852983ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/05 17:14:13 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
      "2026/02/05 17:14:13 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
      "2026/02/05 17:14:13 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
      "2026/02/05 17:14:13 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
      "2026/02/05 17:14:13 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
      "2026/02/05 17:14:13 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
      "2026/02/05 17:14:13 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/02/05 17:14:13 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/02/05 17:14:13 INFO mlflow.tracking.fluent: Experiment with name 'Resnet Scratch Test' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Resnet Scratch Test\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b4a9e15-f5fb-41e4-8dc3-e0d4244016c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/05 17:14:32 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2026/02/05 17:14:32 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Avg training loss - 1.3523036351516133, Avg validation loss - 0.9702402353286743\n",
      "Epoch 2: Avg training loss - 0.7976870521322473, Avg validation loss - 0.9725034832954407\n",
      "Epoch 3: Avg training loss - 0.7592264455418254, Avg validation loss - 0.9696353077888489\n",
      "Epoch 4: Avg training loss - 0.7121802882616779, Avg validation loss - 0.964360773563385\n",
      "Epoch 5: Avg training loss - 0.7150943351998216, Avg validation loss - 0.955269992351532\n",
      "Epoch 6: Avg training loss - 0.6818292151863982, Avg validation loss - 0.9698925614356995\n",
      "Epoch 7: Avg training loss - 0.6705553194990864, Avg validation loss - 0.9670665860176086\n",
      "Epoch 8: Avg training loss - 0.6729383985569448, Avg validation loss - 0.9643304347991943\n",
      "Epoch 9: Avg training loss - 0.639830176661044, Avg validation loss - 0.9508029818534851\n",
      "Epoch 10: Avg training loss - 0.6741301938891411, Avg validation loss - 0.951831042766571\n",
      "Epoch 11: Avg training loss - 0.6189326073652432, Avg validation loss - 0.961796760559082\n",
      "Epoch 12: Avg training loss - 0.6495150217697734, Avg validation loss - 0.9770811200141907\n",
      "Epoch 13: Avg training loss - 0.6255157458377473, Avg validation loss - 0.9367777705192566\n",
      "Epoch 14: Avg training loss - 0.6054866378798204, Avg validation loss - 0.9477895498275757\n",
      "Epoch 15: Avg training loss - 0.6298743070262235, Avg validation loss - 0.9395127296447754\n",
      "Epoch 16: Avg training loss - 0.6047753219503954, Avg validation loss - 0.9687203168869019\n",
      "Epoch 17: Avg training loss - 0.6595978116287905, Avg validation loss - 0.9442138671875\n",
      "Epoch 18: Avg training loss - 0.5935494745219195, Avg validation loss - 0.9326977133750916\n",
      "Epoch 19: Avg training loss - 0.5578228967264295, Avg validation loss - 0.9277412295341492\n",
      "Epoch 20: Avg training loss - 0.5854763195273422, Avg validation loss - 0.9254728555679321\n",
      "Epoch 21: Avg training loss - 0.5824745900928974, Avg validation loss - 0.9286937117576599\n",
      "Epoch 22: Avg training loss - 0.5803883277944156, Avg validation loss - 0.9187695980072021\n",
      "Epoch 23: Avg training loss - 0.5494100735130081, Avg validation loss - 0.9335052371025085\n",
      "Epoch 24: Avg training loss - 0.5085340959903522, Avg validation loss - 0.9324716329574585\n",
      "Epoch 25: Avg training loss - 0.528930298806656, Avg validation loss - 0.9513683319091797\n",
      "Epoch 26: Avg training loss - 0.5805918425321579, Avg validation loss - 0.9402261972427368\n",
      "Epoch 27: Avg training loss - 0.5256837252527475, Avg validation loss - 0.9264009594917297\n",
      "Epoch 28: Avg training loss - 0.509066936870416, Avg validation loss - 0.9349101185798645\n",
      "Epoch 29: Avg training loss - 0.5070198103785515, Avg validation loss - 0.9042956829071045\n",
      "Epoch 30: Avg training loss - 0.467892931819689, Avg validation loss - 0.9061917066574097\n",
      "Epoch 31: Avg training loss - 0.5027471564618158, Avg validation loss - 0.9033611416816711\n",
      "Epoch 32: Avg training loss - 0.4565693186021145, Avg validation loss - 0.9000937342643738\n",
      "Epoch 33: Avg training loss - 0.448959444581372, Avg validation loss - 0.896251916885376\n",
      "Epoch 34: Avg training loss - 0.48288137133581094, Avg validation loss - 0.8982190489768982\n",
      "Epoch 35: Avg training loss - 0.4698637628927827, Avg validation loss - 0.9159948229789734\n",
      "Epoch 36: Avg training loss - 0.45066540587095566, Avg validation loss - 0.9172253608703613\n",
      "Epoch 37: Avg training loss - 0.4523724064230919, Avg validation loss - 0.9099080562591553\n",
      "Epoch 38: Avg training loss - 0.4201376418807084, Avg validation loss - 0.9075133800506592\n",
      "Epoch 39: Avg training loss - 0.3929567801477831, Avg validation loss - 0.8898934125900269\n",
      "Epoch 40: Avg training loss - 0.3955658605713167, Avg validation loss - 0.8728254437446594\n",
      "Epoch 41: Avg training loss - 0.4035300929553625, Avg validation loss - 0.8926449418067932\n",
      "Epoch 42: Avg training loss - 0.3833748583174959, Avg validation loss - 0.8588802814483643\n",
      "Epoch 43: Avg training loss - 0.35160332170234604, Avg validation loss - 0.8822518587112427\n",
      "Epoch 44: Avg training loss - 0.39417266293982917, Avg validation loss - 0.8836214542388916\n",
      "Epoch 45: Avg training loss - 0.36616573088309345, Avg validation loss - 0.8714869618415833\n",
      "Epoch 46: Avg training loss - 0.31955206141066855, Avg validation loss - 0.8788930177688599\n",
      "Epoch 47: Avg training loss - 0.3419843591659902, Avg validation loss - 0.8497297167778015\n",
      "Epoch 48: Avg training loss - 0.3465767001520984, Avg validation loss - 0.880596399307251\n",
      "Epoch 49: Avg training loss - 0.30481213676289487, Avg validation loss - 0.8536733984947205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/05 21:03:33 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2026/02/05 21:03:33 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Avg training loss - 0.3359103193860265, Avg validation loss - 0.8361746072769165\n",
      "üèÉ View run grandiose-kite-447 at: http://127.0.0.1:5000/#/experiments/2/runs/aa2e288c3e2945f0a13bc8f712ed3963\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "mlflow.pytorch.autolog()\n",
    "mlflow.enable_system_metrics_logging()\n",
    "with mlflow.start_run():\n",
    "    params = {'learning_rate': 1e-3, 'epochs': 50, 'output_size': 256, 'batch_size': 15}\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    resnet_model = ResNet(Block, [3, 4, 6, 3], image_channels=3)\n",
    "    loss_fn = TripletMarginLoss()\n",
    "    optimizer = Adam(resnet_model.parameters(), lr=params['learning_rate'])\n",
    "    \n",
    "    for i in range(params['epochs']):\n",
    "        avg_loss = []\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            pred = resnet_model(X)\n",
    "            pairs = create_pairs(y, pred)\n",
    "            anchor_tensor, positive_tensor, negative_tensor = create_tensors(pairs)\n",
    "            loss = loss_fn(anchor_tensor, positive_tensor, negative_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            avg_loss.append(loss.item())\n",
    "        with torch.no_grad():\n",
    "            val_output = []\n",
    "            val_label = []\n",
    "            for j in range(valid_data.__len__()):\n",
    "                X, y = valid_data[j]\n",
    "                reshaped_X = torch.reshape(X, (1, 3, 224, 224))\n",
    "                val_pred = resnet_model(reshaped_X)\n",
    "                val_output.append(torch.flatten(val_pred))\n",
    "                val_label.append(y)\n",
    "            pairs = create_pairs(val_label, val_output)\n",
    "            anchor_tensor, positive_tensor, negative_tensor = create_tensors(pairs)\n",
    "            val_loss = loss_fn(anchor_tensor, positive_tensor, negative_tensor)\n",
    "        print(f\"Epoch {i+1}: Avg training loss - {np.mean(avg_loss)}, Avg validation loss - {val_loss}\")\n",
    "        mlflow.log_metric(\"train_loss\", np.mean(avg_loss), step=i+1)\n",
    "        mlflow.log_metric(\"valid_loss\", val_loss, step=i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8ad9165-c8a4-40b7-8fa6-75c6dffc12ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot \n",
    "from numpy.linalg import norm \n",
    "\n",
    "def cosine_similarity(v1, v2): \n",
    "    return dot(v1, v2) / (norm(v1) * norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "321ffd83-ca76-445b-bf01-d221b69d502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1 = test_data[3]\n",
    "X2, y2 = test_data[0]\n",
    "X3, y3 = test_data[1]\n",
    "# 0, 2 same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4cbbc3b-eacf-42ae-8a32-f98ed0034ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_X = torch.reshape(X2, (1, 3, 224, 224))\n",
    "val_pred = resnet_model(reshaped_X)\n",
    "val_pred_same1 = torch.flatten(val_pred)\n",
    "\n",
    "reshaped_X = torch.reshape(X3, (1, 3, 224, 224))\n",
    "val_pred = resnet_model(reshaped_X)\n",
    "val_pred_same2 = torch.flatten(val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5d66fcf-c8ab-4081-9a0c-77d81cb526d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baljot\\AppData\\Local\\Temp\\ipykernel_31092\\2056708598.py:5: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return dot(v1, v2) / (norm(v1) * norm(v2))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float32(0.9995917)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(val_pred_same1.detach(), val_pred_same2.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a05b66-fb92-43d2-9ee8-206a3cd3cfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
